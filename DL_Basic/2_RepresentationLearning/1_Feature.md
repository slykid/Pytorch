# 1. Feature 란?
- 샘플을 잘 설명하는 특징 <br>
  ex. 나이, 키, 직업, 몸무게, ...

## 1) 좋은 특징과 나쁜 특징
- 좋은 특징 : 성별, 나이, 직업 등 대상을 잘 설명할 수 있는 요소
- 나쁜 특징 : 종류, 유일한 특성(주민등록번호 -> 개수가 많으면 그만큼 저장공간이 필요함)
<br><br>
- 좋은 특징이면 특정 샘플을 수치화할 수 있다.

## 2) 머신러닝으로 가져오면?
- Traditional Machine Learning의 경우
  - 사람이 데이터를 면밀하게 분석한 후, 가정을 세움
  - 가정에 따라 전체리를 통해 feature 를 추출
  - 추출된 feature 를 모델에 넣어 학습
  - 사람이 해석하기 쉽지만, 사람들이 인지하지 못하는 특징들이 존재함

- Current Deep Learning의 경우
  - 원본 데이터에 최소한의 전처리를 수행함(Scaling 등)
  - 전처리된 데이터를 모델에 넣어 학습
  - 구현이 용이하고, 사람이 인지못한 특징을 찾아낼 수 있지만, 사람이 해석하기 어렵다.

# 2. Feature Vector
- 각 특징을 모아서 하나의 벡터로 만든 것
- 벡터의 각 차원은 어떤 속성에 대한 수치를 나타냄
- 특징 벡터를 통해 샘플 간의 유사도를 계산할 수 있음

# 3. One-Hot Encoding
## 1) Categorical vs. Continuous
- 범주형 데이터(Categorical) : 이산적이고, 클래스와 같이 분류 가능한 값
- 수치형 데이터(Continuous) : 연속적이고, 수치로 표현 가능한 값

- 범주형 데이터는 비슷한 값이더라도, 상관 없는 의미를 갖지만, 수치형 데이터는 비슷한 값은 비슷한 의미를 가진다.
  - 범주형 데이터에서는 값의 위치, 상대적인 크기 등에 대해서 의미부여나 해석을 하면 굉장히 잘못된 해석이 될 수 있다.

## 2) One-Hot Encoding
- 크기와 의미를 갖는 정수값 대신 1개의 1과 n-1 개의 0으로 구성된 n차원의 벡터
- 특징 
  - Sparse Vector 임
    - Sparse Vector : Vector의 값 대부분이 0으로 구성된 벡터 ( <-> Dense Vector)

- 문제점
  - 서로 다른 두 벡터는 항상 직교함<br>
  → 두 샘플 간의 유사도 계산이 불가 (코사인 유사도 = 0)<br>
  → Dense Vector로 표현해줘야 유사도 계산이 가능해짐

- 해결방법 : Word2Vec, DNN 등으로 차원 축소 및 Dense Vector 로 표현함